{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27570bf-abb5-41cf-921d-2e68891e759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import di base ---\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Import Modelli ---\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier # Aggiunto kNN\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.feature_builder_Model1 import *\n",
    "\n",
    "\n",
    "from src.config_Model1 import *\n",
    "\n",
    "try:\n",
    "    from src.data_processing import load_jsonl_data, clean_raw_data\n",
    "except ImportError:\n",
    "    print(\"ATTENZIONE: 'load_jsonl_data' non trovato in src.data_processing.py. Verr√† usata la logica locale.\")\n",
    "    \n",
    "    # Definizione locale\n",
    "    def load_jsonl_data(file_path: str) -> pd.DataFrame:\n",
    "        data = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def clean_raw_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_cleaned = df.copy()\n",
    "        ROW_TO_DROP = 4877\n",
    "        if ROW_TO_DROP in df_cleaned.index:\n",
    "            df_cleaned = df_cleaned.drop(index=ROW_TO_DROP)\n",
    "        \n",
    "        print(\"Eseguita pulizia dati locale.\")\n",
    "        return df_cleaned.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Impostazioni\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 123\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "\n",
    "print(\"Librerie e moduli per Model1 importati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7930d-fb16-42b3-b73e-4178accd1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Caricamento e pulizia dati di training...\")\n",
    "\n",
    "# Path\n",
    "BASE_DATA_PATH = os.path.join('..', 'data', 'raw')\n",
    "TRAIN_FILE_PATH = os.path.join(BASE_DATA_PATH, 'train.jsonl')\n",
    "\n",
    "# Carica\n",
    "df_raw_train = load_jsonl_data(TRAIN_FILE_PATH)\n",
    "\n",
    "# Pulisci\n",
    "df_train_cleaned = clean_raw_data(df_raw_train)\n",
    "\n",
    "# Mescola\n",
    "df_train_shuffled = df_train_cleaned.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dati di training pronti. Shape: {df_train_shuffled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15774431-16de-42f8-990d-8d17702c8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generazione Feature Set v8, v19, v20 ---\")\n",
    "\n",
    "# Estrae i set di feature usando le funzioni importate\n",
    "X_train_v8, y_train = build_feature_dataframe(df_train_shuffled, extract_features_v8, is_test_set=False)\n",
    "X_train_v20, _ = build_feature_dataframe(df_train_shuffled, extract_features_v20, is_test_set=False)\n",
    "X_train_v19, _ = build_feature_dataframe(df_train_shuffled, extract_features_v19, is_test_set=False)\n",
    "\n",
    "print(\"\\n--- Shape dei Feature Set Creati ---\")\n",
    "print(f\"X_train_v8 (per LR-v8):        {X_train_v8.shape}\")\n",
    "print(f\"X_train_v20 (per XGB):         {X_train_v20.shape}\")\n",
    "print(f\"X_train_v19 (per RF/CAT/kNN): {X_train_v19.shape}\")\n",
    "print(f\"y_train (Target):              {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c8275-80fd-4ca1-a2df-036e16d967eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Salvataggio Feature Set in data/processed/ ---\")\n",
    "\n",
    "PROCESSED_PATH = os.path.join('..', 'data', 'processed')\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "# Salva V8\n",
    "X_train_v8.to_csv(os.path.join(PROCESSED_PATH, 'v8_train_features.csv'), index=False)\n",
    "print(\"Salvataggio v8_train_features.csv completato.\")\n",
    "\n",
    "# Salva V20\n",
    "X_train_v20.to_csv(os.path.join(PROCESSED_PATH, 'v20_train_features.csv'), index=False)\n",
    "print(\"Salvataggio v20_train_features.csv completato.\")\n",
    "\n",
    "# Salva V19\n",
    "X_train_v19.to_csv(os.path.join(PROCESSED_PATH, 'v19_train_features.csv'), index=False)\n",
    "print(\"Salvataggio v19_train_features.csv completato.\")\n",
    "\n",
    "# Salva il Target\n",
    "y_train_df = y_train.to_frame(name='player_won')\n",
    "y_train_df.to_csv(os.path.join(PROCESSED_PATH, 'train_target.csv'), index=False)\n",
    "print(\"Salvataggio train_target.csv completato.\")\n",
    "\n",
    "print(\"\\nDone! I file sono pronti per '02_All_Base_Models_Training.ipynb'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5345f5e-732d-4bab-80e6-a1a59369292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenitore per i nostri modelli base\n",
    "base_models = {}\n",
    "\n",
    "# === 1. Modello LR (v8) ===\n",
    "# Da: prova-xg-vs-logistic-v2.ipynb\n",
    "model_lr_v8 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        C=10.0, \n",
    "        penalty='l2', \n",
    "        solver='saga', \n",
    "        max_iter=5000, \n",
    "        random_state=SEED\n",
    "    ))\n",
    "])\n",
    "base_models['lr_v8'] = (model_lr_v8, X_train_v8)\n",
    "\n",
    "# === 2. Modello XGB (v20) ===\n",
    "# Da: xg-vs-logit-con-switch-strategy.ipynb\n",
    "model_xgb_v20 = XGBClassifier(\n",
    "    colsample_bytree=0.7,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    n_estimators=200,\n",
    "    reg_lambda=5,\n",
    "    subsample=0.7,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=SEED\n",
    ")\n",
    "base_models['xgb_v20'] = (model_xgb_v20, X_train_v20)\n",
    "\n",
    "# === 3. Modello RF (v19) ===\n",
    "# Da: random-forrest.ipynb\n",
    "model_rf_v19 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features=0.5,\n",
    "        max_depth=10,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "base_models['rf_v19'] = (model_rf_v19, X_train_v19)\n",
    "\n",
    "# === 4. Modello CAT (v19) ===\n",
    "# Da: knn-vs-catboost.ipynb\n",
    "model_cat_v19 = CatBoostClassifier(\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=7,\n",
    "    iterations=300,\n",
    "    depth=8,\n",
    "    random_state=SEED,\n",
    "    verbose=0,\n",
    "    eval_metric='Accuracy'\n",
    ")\n",
    "base_models['cat_v19'] = (model_cat_v19, X_train_v19)\n",
    "\n",
    "# === 5. Modello kNN (v19) ===\n",
    "# Da: knn-vs-catboost.ipynb\n",
    "model_knn_v19 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', KNeighborsClassifier(\n",
    "        metric='manhattan',\n",
    "        n_neighbors=45,\n",
    "        weights='uniform',\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "base_models['knn_v19'] = (model_knn_v19, X_train_v19)\n",
    "\n",
    "\n",
    "print(f\"Definiti {len(base_models)} modelli base pronti per lo stacking.\")\n",
    "print(f\"Modelli nello stack: {list(base_models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d419297-0f62-4766-b31b-f0708414f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "kfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Creiamo il DataFrame X_meta per le OOF predictions\n",
    "oof_preds = np.zeros((len(y_train), len(base_models)))\n",
    "X_meta_df = pd.DataFrame(oof_preds, columns=base_models.keys())\n",
    "\n",
    "# Modelli che serviranno per la submission (addestrati su tutto)\n",
    "final_base_models = {}\n",
    "\n",
    "print(f\"Avvio Stacking (OOF) con {N_SPLITS} folds...\")\n",
    "\n",
    "# Usiamo tqdm per una barra di progresso\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(kfold.split(y_train, y_train), total=N_SPLITS, desc=\"Folds\")):\n",
    "    \n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    for name, (model, X_data) in base_models.items():\n",
    "        # Prendi i dati di training/validazione per *questo* set di feature\n",
    "        X_train_fold = X_data.iloc[train_idx]\n",
    "        X_val_fold = X_data.iloc[val_idx]\n",
    "        \n",
    "        # Addestra il modello\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Salva le previsioni OOF (probabilit√†)\n",
    "        X_meta_df.loc[val_idx, name] = model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "print(\"\\nCreazione Meta-Features (X_meta_df) completata.\")\n",
    "\n",
    "# Ora, addestra i modelli base sull'INTERO dataset di training\n",
    "# Ci serviranno per predire sul test set\n",
    "print(\"Addestramento modelli base finali su tutti i dati di training...\")\n",
    "for name, (model, X_data) in tqdm(base_models.items(), desc=\"Modelli Finali\"):\n",
    "    final_base_models[name] = model.fit(X_data, y_train)\n",
    "\n",
    "print(\"Modelli base finali addestrati.\")\n",
    "display(X_meta_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026a85a-b5f4-4bbf-a0c3-24971eaba2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Correlazione delle Previsioni OOF (Meta-Features) ---\")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    X_meta_df.corr(), \n",
    "    annot=True, \n",
    "    cmap='coolwarm', \n",
    "    fmt=\".3f\"\n",
    ")\n",
    "plt.title(f\"Correlazione Modelli Base (Stack {list(base_models.keys())})\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Commento: Cerchiamo valori pi√π bassi possibile.\")\n",
    "print(\"Il kNN dovrebbe avere una correlazione pi√π bassa con gli altri, il che √® ottimo per l'ensemble.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd6b16-71d1-4962-ab23-7548b9092eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ANALISI ENSEMBLE - SELEZIONE MODELLI OTTIMALE\n",
    "==============================================\n",
    "\n",
    "Questo codice va inserito DOPO la cella 8 (dopo aver creato X_meta_df)\n",
    "e PRIMA della cella 9 (addestramento meta-modello finale)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALISI ENSEMBLE - SELEZIONE MODELLI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# METODO 1: PERFORMANCE INDIVIDUALI (OOF)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METODO 1: PERFORMANCE INDIVIDUALI DEI MODELLI BASE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcola accuracy OOF per ogni modello singolarmente\n",
    "individual_scores = {}\n",
    "for name in X_meta_df.columns:\n",
    "    # Predici con threshold 0.5\n",
    "    predictions = (X_meta_df[name] > 0.5).astype(int)\n",
    "    accuracy = (predictions == y_train).mean()\n",
    "    individual_scores[name] = accuracy\n",
    "    \n",
    "# Ordina per performance\n",
    "sorted_scores = dict(sorted(individual_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print(\"\\nACCURACY OOF INDIVIDUALE:\")\n",
    "print(\"-\" * 50)\n",
    "for name, score in sorted_scores.items():\n",
    "    print(f\"{name:10s}: {score:.4f}\")\n",
    "\n",
    "# Visualizza\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(list(sorted_scores.keys()), list(sorted_scores.values()), color='steelblue')\n",
    "plt.xlabel('OOF Accuracy')\n",
    "plt.title('Performance Individuale Modelli Base')\n",
    "plt.xlim([min(sorted_scores.values())-0.01, max(sorted_scores.values())+0.01])\n",
    "for i, (name, score) in enumerate(sorted_scores.items()):\n",
    "    plt.text(score, i, f' {score:.4f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# METODO 2: CORRELAZIONE PREDIZIONI (GI√Ä HAI LA HEATMAP)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METODO 2: ANALISI CORRELAZIONE PREDIZIONI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlation_matrix = X_meta_df.corr()\n",
    "print(\"\\nMATRICE DI CORRELAZIONE:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Trova coppie ad alta correlazione (>0.9 = ridondanti)\n",
    "print(\"\\n‚ö†Ô∏è  COPPIE AD ALTA CORRELAZIONE (>0.90 - Potenziale Ridondanza):\")\n",
    "print(\"-\" * 50)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if corr_value > 0.90:\n",
    "            pair = (correlation_matrix.columns[i], correlation_matrix.columns[j], corr_value)\n",
    "            high_corr_pairs.append(pair)\n",
    "            print(f\"{pair[0]:10s} <-> {pair[1]:10s}: {pair[2]:.4f}\")\n",
    "\n",
    "if not high_corr_pairs:\n",
    "    print(\"‚úì Nessuna coppia con correlazione >0.90 (Buona diversit√†!)\")\n",
    "\n",
    "# Media correlazione per modello (quanto √® simile agli altri)\n",
    "avg_corr = {}\n",
    "for col in correlation_matrix.columns:\n",
    "    # Media correlazioni con altri modelli (escluso se stesso)\n",
    "    other_corrs = correlation_matrix[col].drop(col)\n",
    "    avg_corr[col] = other_corrs.mean()\n",
    "\n",
    "print(\"\\nüìä MEDIA CORRELAZIONE CON ALTRI MODELLI:\")\n",
    "print(\"-\" * 50)\n",
    "for name, avg in sorted(avg_corr.items(), key=lambda x: x[1]):\n",
    "    print(f\"{name:10s}: {avg:.4f} {'‚≠ê (Pi√π diverso)' if avg == min(avg_corr.values()) else ''}\")\n",
    "\n",
    "# ============================================================================\n",
    "# METODO 3: BACKWARD ELIMINATION (Rimuovi uno alla volta)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METODO 3: BACKWARD ELIMINATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"(Rimuove modelli uno alla volta, verifica impatto su CV score)\\n\")\n",
    "\n",
    "meta_model = LogisticRegression(random_state=SEED, max_iter=1000)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score baseline (tutti i modelli)\n",
    "baseline_score = cross_val_score(\n",
    "    meta_model, X_meta_df, y_train, cv=kfold, scoring='accuracy', n_jobs=-1\n",
    ").mean()\n",
    "\n",
    "print(f\"üìå BASELINE (Tutti i {len(X_meta_df.columns)} modelli): {baseline_score:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Prova a rimuovere ogni modello singolarmente\n",
    "removal_impact = {}\n",
    "for col_to_remove in X_meta_df.columns:\n",
    "    X_reduced = X_meta_df.drop(columns=[col_to_remove])\n",
    "    score = cross_val_score(\n",
    "        meta_model, X_reduced, y_train, cv=kfold, scoring='accuracy', n_jobs=-1\n",
    "    ).mean()\n",
    "    impact = score - baseline_score\n",
    "    removal_impact[col_to_remove] = {'score': score, 'impact': impact}\n",
    "    \n",
    "    emoji = \"üìâ\" if impact < 0 else \"üìà\" if impact > 0 else \"‚û°Ô∏è\"\n",
    "    print(f\"{emoji} Senza {col_to_remove:10s}: {score:.4f} (Œî = {impact:+.4f})\")\n",
    "\n",
    "# Trova il modello la cui rimozione danneggia meno (o migliora)\n",
    "least_damaging = max(removal_impact.items(), key=lambda x: x[1]['impact'])\n",
    "print(f\"\\nüí° CANDIDATO ALLA RIMOZIONE: {least_damaging[0]}\")\n",
    "print(f\"   Score senza: {least_damaging[1]['score']:.4f}\")\n",
    "print(f\"   Impatto: {least_damaging[1]['impact']:+.4f}\")\n",
    "\n",
    "if least_damaging[1]['impact'] >= 0:\n",
    "    print(f\"   ‚úì Rimuoverlo MIGLIORA o non peggiora il modello!\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Rimuoverlo peggiora il modello di {abs(least_damaging[1]['impact']):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# METODO 4: FORWARD SELECTION (Costruisci dal migliore)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METODO 4: FORWARD SELECTION\")\n",
    "print(\"=\"*80)\n",
    "print(\"(Parte dal modello migliore, aggiunge uno alla volta quello che migliora di pi√π)\\n\")\n",
    "\n",
    "# Ordina modelli per performance individuale\n",
    "sorted_models = sorted(individual_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Inizia col migliore\n",
    "selected = [sorted_models[0][0]]\n",
    "remaining = [m[0] for m in sorted_models[1:]]\n",
    "\n",
    "print(f\"üìå INIZIO CON: {selected[0]} (Accuracy: {sorted_models[0][1]:.4f})\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "forward_history = []\n",
    "current_score = cross_val_score(\n",
    "    meta_model, X_meta_df[selected], y_train, cv=kfold, scoring='accuracy', n_jobs=-1\n",
    ").mean()\n",
    "forward_history.append({'models': selected.copy(), 'score': current_score})\n",
    "\n",
    "print(f\"CV Score con [{', '.join(selected)}]: {current_score:.4f}\\n\")\n",
    "\n",
    "# Aggiungi modelli uno alla volta\n",
    "while remaining:\n",
    "    best_addition = None\n",
    "    best_score = current_score\n",
    "    \n",
    "    for candidate in remaining:\n",
    "        test_set = selected + [candidate]\n",
    "        score = cross_val_score(\n",
    "            meta_model, X_meta_df[test_set], y_train, cv=kfold, scoring='accuracy', n_jobs=-1\n",
    "        ).mean()\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_addition = candidate\n",
    "    \n",
    "    if best_addition is not None:\n",
    "        selected.append(best_addition)\n",
    "        remaining.remove(best_addition)\n",
    "        current_score = best_score\n",
    "        forward_history.append({'models': selected.copy(), 'score': current_score})\n",
    "        \n",
    "        improvement = current_score - forward_history[-2]['score']\n",
    "        print(f\"‚ûï Aggiunto {best_addition:10s}: {current_score:.4f} (Œî = +{improvement:.4f})\")\n",
    "    else:\n",
    "        print(f\"\\n‚õî STOP: Nessun modello migliora ulteriormente il CV score\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nüèÜ MIGLIOR COMBINAZIONE (Forward): {selected}\")\n",
    "print(f\"   CV Score: {current_score:.4f}\")\n",
    "\n",
    "# Visualizza storia Forward Selection\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "scores = [h['score'] for h in forward_history]\n",
    "labels = [f\"{i+1}: {', '.join(h['models'][:2])}...\" if len(h['models']) > 2 \n",
    "          else f\"{i+1}: {', '.join(h['models'])}\" \n",
    "          for i, h in enumerate(forward_history)]\n",
    "ax.plot(range(1, len(scores)+1), scores, marker='o', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Numero di Modelli nell\\'Ensemble')\n",
    "ax.set_ylabel('CV Accuracy')\n",
    "ax.set_title('Forward Selection: Andamento CV Score')\n",
    "ax.set_xticks(range(1, len(scores)+1))\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.axhline(baseline_score, color='red', linestyle='--', label=f'Baseline (tutti): {baseline_score:.4f}')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# METODO 5: PROVA TUTTE LE COMBINAZIONI (Brute Force - Per 5 modelli √® fattibile)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METODO 5: VALUTAZIONE TUTTE LE COMBINAZIONI\")\n",
    "print(\"=\"*80)\n",
    "print(f\"(Con {len(X_meta_df.columns)} modelli ci sono {2**len(X_meta_df.columns)-1} combinazioni possibili)\\n\")\n",
    "\n",
    "all_models = list(X_meta_df.columns)\n",
    "all_combinations = []\n",
    "\n",
    "# Prova tutte le combinazioni da 1 a N modelli\n",
    "for size in range(1, len(all_models) + 1):\n",
    "    for combo in combinations(all_models, size):\n",
    "        score = cross_val_score(\n",
    "            meta_model, X_meta_df[list(combo)], y_train, cv=kfold, scoring='accuracy', n_jobs=-1\n",
    "        ).mean()\n",
    "        all_combinations.append({\n",
    "            'models': list(combo),\n",
    "            'n_models': len(combo),\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "# Ordina per score\n",
    "all_combinations_sorted = sorted(all_combinations, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "print(\"üèÜ TOP 10 COMBINAZIONI:\")\n",
    "print(\"-\" * 80)\n",
    "for i, combo in enumerate(all_combinations_sorted[:10], 1):\n",
    "    models_str = ', '.join(combo['models'])\n",
    "    print(f\"{i:2d}. [{combo['n_models']} modelli] {combo['score']:.4f} - {models_str}\")\n",
    "\n",
    "# Migliore per ogni numero di modelli\n",
    "print(\"\\nüìä MIGLIOR COMBINAZIONE PER NUMERO DI MODELLI:\")\n",
    "print(\"-\" * 80)\n",
    "best_by_size = {}\n",
    "for combo in all_combinations:\n",
    "    size = combo['n_models']\n",
    "    if size not in best_by_size or combo['score'] > best_by_size[size]['score']:\n",
    "        best_by_size[size] = combo\n",
    "\n",
    "for size in sorted(best_by_size.keys()):\n",
    "    combo = best_by_size[size]\n",
    "    models_str = ', '.join(combo['models'])\n",
    "    print(f\"{size} modelli: {combo['score']:.4f} - [{models_str}]\")\n",
    "\n",
    "# Visualizza\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for size in sorted(best_by_size.keys()):\n",
    "    scores_for_size = [c['score'] for c in all_combinations if c['n_models'] == size]\n",
    "    ax.scatter([size] * len(scores_for_size), scores_for_size, alpha=0.3, s=50)\n",
    "    \n",
    "# Linea dei migliori\n",
    "best_scores = [best_by_size[s]['score'] for s in sorted(best_by_size.keys())]\n",
    "ax.plot(sorted(best_by_size.keys()), best_scores, 'ro-', linewidth=2, markersize=10, label='Best per size')\n",
    "ax.axhline(baseline_score, color='green', linestyle='--', linewidth=2, label=f'Baseline (tutti): {baseline_score:.4f}')\n",
    "ax.set_xlabel('Numero di Modelli nell\\'Ensemble')\n",
    "ax.set_ylabel('CV Accuracy')\n",
    "ax.set_title('Tutte le Combinazioni: CV Score vs Numero di Modelli')\n",
    "ax.set_xticks(sorted(best_by_size.keys()))\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# RIEPILOGO FINALE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã RIEPILOGO E RACCOMANDAZIONI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  BASELINE (Tutti i {len(X_meta_df.columns)} modelli):\")\n",
    "print(f\"   CV Score: {baseline_score:.4f}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  BACKWARD ELIMINATION suggerisce:\")\n",
    "print(f\"   Rimuovere: {least_damaging[0]}\")\n",
    "print(f\"   Score risultante: {least_damaging[1]['score']:.4f}\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  FORWARD SELECTION suggerisce:\")\n",
    "print(f\"   Modelli: {selected}\")\n",
    "print(f\"   Score: {current_score:.4f}\")\n",
    "\n",
    "print(f\"\\n4Ô∏è‚É£  MIGLIOR COMBINAZIONE ASSOLUTA (Brute Force):\")\n",
    "best_overall = all_combinations_sorted[0]\n",
    "print(f\"   Modelli: {best_overall['models']}\")\n",
    "print(f\"   Score: {best_overall['score']:.4f}\")\n",
    "\n",
    "# Confronto con baseline\n",
    "improvement = best_overall['score'] - baseline_score\n",
    "if improvement > 0.0005:  # Miglioramento significativo\n",
    "    print(f\"\\n‚úÖ RACCOMANDAZIONE: Usa la combinazione ottimale trovata\")\n",
    "    print(f\"   Miglioramento: +{improvement:.4f}\")\n",
    "    print(f\"   Modelli da usare: {best_overall['models']}\")\n",
    "elif improvement < -0.0005:  # Peggioramento\n",
    "    print(f\"\\n‚ö†Ô∏è  RACCOMANDAZIONE: Mantieni tutti i modelli (baseline)\")\n",
    "    print(f\"   La combinazione ottimale √® peggiore: {improvement:.4f}\")\n",
    "else:  # Differenza trascurabile\n",
    "    print(f\"\\n‚û°Ô∏è  RACCOMANDAZIONE: Baseline vs Ottimale sono equivalenti\")\n",
    "    print(f\"   Differenza trascurabile: {improvement:.4f}\")\n",
    "    if len(best_overall['models']) < len(X_meta_df.columns):\n",
    "        print(f\"   Suggerisco: Usa {best_overall['models']} (pi√π semplice)\")\n",
    "    else:\n",
    "        print(f\"   Suggerisco: Mantieni tutti (pi√π robusto)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° SUGGERIMENTI AGGIUNTIVI:\")\n",
    "print(\"=\"*80)\n",
    "print(\"- Se hai modelli con correlazione >0.95, considera di rimuovere il pi√π debole\")\n",
    "print(\"- kNN spesso ha bassa correlazione ma pu√≤ essere debole individualmente\")\n",
    "print(\"- XGBoost e CatBoost tendono ad essere correlati (entrambi gradient boosting)\")\n",
    "print(\"- Il meta-modello (LogReg) pu√≤ dare pesi diversi ai modelli automaticamente\")\n",
    "print(\"- Se il dataset √® piccolo, meno modelli = meno overfitting del meta-modello\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# CREA SUBSET OTTIMALE PER PROSSIMI STEP\n",
    "# ============================================================================\n",
    "print(f\"\\nüîß Creazione X_meta_df ottimizzato...\")\n",
    "optimal_models = best_overall['models']\n",
    "X_meta_df_optimal = X_meta_df[optimal_models].copy()\n",
    "print(f\"   X_meta_df_optimal creato con modelli: {optimal_models}\")\n",
    "print(f\"   Usa 'X_meta_df_optimal' nella cella successiva per il meta-modello finale\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c476aa-576b-4624-aefb-24309ac4cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Addestramento e Valutazione Meta-Modello (Livello 1) ---\")\n",
    "\n",
    "# Un modello semplice √® la scelta migliore per il meta-modello.\n",
    "meta_model = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Valutiamo il nostro ensemble finale usando la CV\n",
    "# Questo ci d√† lo score pi√π onesto\n",
    "cv_scores = cross_val_score(\n",
    "    meta_model, \n",
    "    X_meta_df_optimal,  # Le nostre feature di Livello 1 (le previsioni OOF)\n",
    "    y_train,    # I target reali\n",
    "    cv=kfold, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nScore CV dell'Ensemble Finale (Stima Onesta):\")\n",
    "print(f\"Accuracy: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Scores dei Fold: {[round(s, 4) for s in cv_scores]}\")\n",
    "\n",
    "\n",
    "# Addestra il meta-modello finale sul SET OTTIMALE di meta-feature OOF\n",
    "print(f\"Addestramento del Meta-Modello finale su X_meta_df_optimal ({X_meta_df_optimal.shape})...\")\n",
    "final_ensemble_model = meta_model.fit(X_meta_df_optimal, y_train)\n",
    "print(\"Meta-Modello pronto per la submission!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95306a08-1c24-4d7d-b809-85794b274159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Preparazione Dati di Test per la Submission ---\")\n",
    "\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "test_data_raw = []\n",
    "\n",
    "print(f\"Caricamento dati di TEST da '{test_file_path}'...\")\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data_raw.append(json.loads(line))\n",
    "df_test_raw = pd.DataFrame(test_data_raw) \n",
    "\n",
    "# --- Applica TUTTE le Feature Engineering ---\n",
    "print(\"Generazione di tutti i Feature Set di Test...\")\n",
    "\n",
    "X_test_v8  = build_feature_dataframe(df_test_raw, extract_features_v8, is_test_set=True)\n",
    "X_test_v20 = build_feature_dataframe(df_test_raw, extract_features_v20, is_test_set=True)\n",
    "X_test_v19 = build_feature_dataframe(df_test_raw, extract_features_v19, is_test_set=True)\n",
    "\n",
    "print(\"\\n--- Shape dei Feature Set di Test ---\")\n",
    "print(f\"X_test_v8:  {X_test_v8.shape}\")\n",
    "print(f\"X_test_v20: {X_test_v20.shape}\")\n",
    "print(f\"X_test_v19: {X_test_v19.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6eb57-84ca-4c0f-a9c3-8c8ce5490ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Creazione Meta-Features di Test ---\")\n",
    "\n",
    "# Dizionario per i dati di test\n",
    "test_data_map = {\n",
    "    'lr_v8': X_test_v8,\n",
    "    'xgb_v20': X_test_v20,\n",
    "    'rf_v19': X_test_v19,\n",
    "    'cat_v19': X_test_v19,\n",
    "    'knn_v19': X_test_v19  # kNN usa le feature v19\n",
    "}\n",
    "\n",
    "# DataFrame vuoto per le previsioni di test\n",
    "X_meta_test_df = pd.DataFrame(columns=base_models.keys())\n",
    "\n",
    "for name, model in tqdm(final_base_models.items(), desc=\"Predizioni Test L0\"):\n",
    "    # Prendi il set di feature di test corrispondente\n",
    "    X_test_data = test_data_map[name]\n",
    "    \n",
    "    # Predici le probabilit√†\n",
    "    X_meta_test_df[name] = model.predict_proba(X_test_data)[:, 1]\n",
    "\n",
    "print(\"Meta-Features di Test create.\")\n",
    "display(X_meta_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13c1c9-bf29-4149-bc05-f18e404e02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generazione Submission Finale ---\")\n",
    "# Filtra le meta-feature di test per usare solo i modelli ottimali\n",
    "# (La variabile 'optimal_models' √® stata definita nella Cella 9)\n",
    "print(f\"Filtraggio delle meta-feature di test sui modelli ottimali: {optimal_models}\")\n",
    "X_meta_test_optimal_SUB = X_meta_test_df[optimal_models]\n",
    "# Usa il meta-modello addestrato (Cella 8) per predire sulle meta-feature di test\n",
    "final_predictions = final_ensemble_model.predict(X_meta_test_optimal_SUB)\n",
    "print(\"Previsioni finali generate.\")\n",
    "\n",
    "# --- Creazione File Submission ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': df_test_raw['battle_id'],\n",
    "    'player_won': final_predictions.astype(int)\n",
    "})\n",
    "\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"File '{submission_filename}' creato con successo!\")\n",
    "print(\"In bocca al lupo per la competizione!\")\n",
    "display(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
