{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184a6dc0",
   "metadata": {},
   "source": [
    "Importing libraries and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628963a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import sys\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Adding src folder\n",
    "sys.path.append('../') \n",
    "\n",
    "from src.feature_builder_Model2 import(\n",
    "    extract_features_v8,\n",
    "    extract_features_v20,\n",
    "    build_feature_dataframe\n",
    ")\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 123 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# PARTE 1: TRAINING META-MODEL (LEVEL 1)\n",
    "# ================================================\n",
    "\n",
    "# Loading training data for the meta-model\n",
    "\n",
    "print(\"Caricamento meta-features e target per il training del meta-modello...\")\n",
    "\n",
    "try:\n",
    "    X_meta_train = pd.read_csv('../data/processed/meta_features_optimal_train.csv')\n",
    "    y_meta_train = pd.read_csv('../data/processed/train_target.csv').squeeze()\n",
    "\n",
    "    print(f\"Meta-features (X_train L1) caricate. Shape: {X_meta_train.shape}\")\n",
    "    print(f\"Target (y_train L1) caricati. Shape: {y_meta_train.shape}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERRORE: File non trovato. {e}\")\n",
    "    print(\"!!! Assicurati di aver prima ESEGUITO il notebook 05_All_Base_Models_Training.ipynb !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b16d10",
   "metadata": {},
   "source": [
    "Training the Meta-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and saving meta-model\n",
    "print(\"--- Training Meta-Modello (Livello 1)... ---\")\n",
    "\n",
    "final_ensemble_model = LogisticRegression(random_state=SEED, max_iter=1000)\n",
    "\n",
    "final_ensemble_model.fit(X_meta_train, y_meta_train)\n",
    "\n",
    "print(\"Meta-Modello allenato.\")\n",
    "\n",
    "META_MODEL_PATH = '../models/final_ensemble_model.joblib'\n",
    "joblib.dump(final_ensemble_model, META_MODEL_PATH)\n",
    "print(f\"Meta-Modello Finale salvato in: {META_MODEL_PATH}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f641df",
   "metadata": {},
   "source": [
    "Generating the Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50319a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loading data function\n",
    "\n",
    "def carica_dati_jsonl(file_path):\n",
    "    \"\"\"Carica un file .jsonl e lo restituisce como DataFrame.\"\"\"\n",
    "    print(f\"Caricamento dati da: {file_path}...\")\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df_raw = pd.DataFrame(data)\n",
    "    return df_raw\n",
    "\n",
    "print(\"Funzione 'carica_dati_jsonl' definita localmente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b718fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# GENERATE SUBMISSION\n",
    "# ================================================\n",
    "\n",
    "print(\"--- Generazione Submission ---\")\n",
    "print(\"Caricamento dati di TEST grezzi...\")\n",
    "TEST_DATA_PATH = '../data/raw/test.jsonl'\n",
    "\n",
    "df_raw_test = carica_dati_jsonl(TEST_DATA_PATH)\n",
    "\n",
    "print(f\"Dati di test caricati. Shape: {df_raw_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature test\n",
    "\n",
    "print(\"Generazione feature v8 per il TEST SET...\")\n",
    "X_test_v8 = build_feature_dataframe(df_raw_test, extract_features_v8, is_test_set=True)\n",
    "\n",
    "print(\"\\nGenerazione feature v20 per il TEST SET...\")\n",
    "X_test_v20 = build_feature_dataframe(df_raw_test, extract_features_v20, is_test_set=True)\n",
    "\n",
    "print(\"\\nFeature di test generate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56767c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Caricamento modelli base ottimali (L0) da /models/...\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    model_lr_v8 = joblib.load('../models/lr_v8.joblib')\n",
    "    model_xgb_v20 = joblib.load('../models/xgb_v20.joblib')\n",
    "\n",
    "    print(\"Modelli base caricati.\")\n",
    "\n",
    "    X_meta_test = pd.DataFrame()\n",
    "\n",
    "    print(\"Generazione predizioni L0 sul test set...\")\n",
    "    X_meta_test['lr_v8'] = model_lr_v8.predict_proba(X_test_v8)[:, 1]\n",
    "    X_meta_test['xgb_v20'] = model_xgb_v20.predict_proba(X_test_v20)[:, 1]\n",
    "\n",
    "    print(f\"Meta-features di test (X_test L1) create. Shape: {X_meta_test.shape}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ERRORE: Modello non trovato. {e}\")\n",
    "    print(\"!!! Assicurati di aver ESEGUITO il notebook 05_All_Base_Models_Training.ipynb !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee785467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generazione Predizioni Finali (L1) ---\")\n",
    "\n",
    "final_ensemble_model = joblib.load('../models/final_ensemble_model.joblib')\n",
    "\n",
    "# Making predictions\n",
    "final_predictions = final_ensemble_model.predict(X_meta_test)\n",
    "\n",
    "print(\"Predizioni finali generate.\")\n",
    "\n",
    "# --- Generating submission file ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': df_raw_test['battle_id'],\n",
    "    'player_won': final_predictions.astype(int)\n",
    "})\n",
    "\n",
    "submission_df.to_csv('../submissions/submission.csv', index=False)\n",
    "\n",
    "print(\"\\n=================================================\")\n",
    "print(\"ðŸŽ‰ SUBMISSION.CSV CREATO CON SUCCESSO! ðŸŽ‰\")\n",
    "print(\"=================================================\")\n",
    "display(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
